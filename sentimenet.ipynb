{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimenet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKT3xS0I9wZt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import re\n",
        "import nltk\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmjecUf9-c4F",
        "outputId": "b80b1fcd-0259-4096-b4d7-f02bb560fbf6"
      },
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/twitter.csv\")\n",
        "print(data.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  ...  class                                              tweet\n",
            "0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
            "1           1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
            "2           2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
            "3           3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
            "4           4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
            "\n",
            "[5 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ADR2bN-c6n",
        "outputId": "c3b4698f-5229-4f9a-b6ce-237f59c5eacf"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")   #\"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language.\"\n",
        "from nltk.corpus import stopwords #Corpora is a group presenting multiple collections of text documents. A single collection is called corpus\n",
        "import string\n",
        "stopword=set(stopwords.words('english'))\n",
        "def clean(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = [word for word in text.split(' ') if word not in stopword]\n",
        "    text=\" \".join(text)\n",
        "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
        "    text=\" \".join(text)\n",
        "    return text\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(clean)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzmuvsvy-c8e",
        "outputId": "ffa75123-c215-4eaf-9be8-300d5d11ac77"
      },
      "source": [
        "#check and assign the text how much positive ,negative and netural \n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon') # VADER belongs to a type of sentiment analysis that is based on lexicons of sentiment-related words. In this approach, each of the words in the lexicon is rated as to whether it is positive or negative, and in many cases, how positive or negative.\n",
        "sentiments = SentimentIntensityAnalyzer()\n",
        "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"tweet\"]]\n",
        "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"tweet\"]]\n",
        "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"tweet\"]]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouZm_VsgFAkP",
        "outputId": "236af72e-2c84-477a-c4ae-96e5a1808821"
      },
      "source": [
        "#select the columns from this data that we need for the rest of the task of Twitter sentiment analysis\n",
        "data = data[[\"tweet\", \"Positive\", \n",
        "             \"Negative\", \"Neutral\"]]\n",
        "print(data.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  ...  Neutral\n",
            "0   rt mayasolov woman shouldnt complain clean ho...  ...    0.696\n",
            "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...  ...    0.720\n",
            "2   rt urkindofbrand dawg rt  ever fuck bitch sta...  ...    0.423\n",
            "3             rt cganderson vivabas look like tranni  ...    0.667\n",
            "4   rt shenikarobert shit hear might true might f...  ...    0.440\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3Nmv4Z-dAL",
        "outputId": "bb3c6de1-7530-48f7-9b87-7c304ee1aa05"
      },
      "source": [
        "x = sum(data[\"Positive\"])\n",
        "y = sum(data[\"Negative\"])\n",
        "z = sum(data[\"Neutral\"])\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "\n",
        "def sentiment_score(a, b, c):\n",
        "    if (a>b) and (a>c):\n",
        "        print(\"Positive ðŸ˜Š \")\n",
        "    elif (b>a) and (b>c):\n",
        "        print(\"Negative ðŸ˜  \")\n",
        "    else:\n",
        "        print(\"Neutral ðŸ™‚ \")\n",
        "sentiment_score(x, y, z)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2880.086000000009\n",
            "7201.020999999922\n",
            "14696.887999999733\n",
            "Neutral ðŸ™‚ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPI3XH9H-dEE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oudvRDDm-dGZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygq-ozNs-dIO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KlTJQuO-dKN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNiwt-zt-dL2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHwTITlG-dOO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}